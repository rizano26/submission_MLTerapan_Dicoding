# -*- coding: utf-8 -*-
"""proyek_pertama_ml_terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wFWvHqGpUnKrroK0ozm4DC7wLO63Uz0K

# Proyek 1 Machine Learning Terapan

## Data Understanding
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### Menampilkan Sampel dari Dataset"""

df = pd.read_csv('framingham.csv')
df.head()

"""### Menampilkan Info dari Dataset"""

df.info()

"""### Menampilkan jumlah missing value pada atribut"""

df.isnull().sum()

"""### Menampilkan deskripsi statistik pada dataset"""

df.describe()

"""### Menampilkan boxplot pada setiap fitur"""

# Visualisasi boxplot terhadap setiap fitur (kecuali TenYearCHD)
plt.figure(figsize=(20, 15))
df.drop(columns='TenYearCHD').boxplot()
plt.xticks(rotation=90)
plt.title('Boxplot of Features')
plt.show()

"""### Jumlah Outliers di setiap fitur"""

# Menghitung jumlah outlier pada setiap fitur (kecuali TenYearCHD)
outliers = {}
for column in df.columns:
    if column != 'TenYearCHD':  # Mengabaikan fitur TenYearCHD
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]

# Menampilkan jumlah outlier pada setiap fitur
print("Jumlah Outlier pada Setiap Fitur (kecuali TenYearCHD):")
for feature, num_outliers in outliers.items():
    print(f"{feature}: {num_outliers} outliers")

"""### Menampilkan jumlah Target (TenYearCHD) pada setiap value"""

df['TenYearCHD'].value_counts()

# Visualisasi value counts terhadap target (TenYearCHD)
plt.figure(figsize=(6, 4))
sns.countplot(x='TenYearCHD', data=df)
plt.title('Value Counts of TenYearCHD')
plt.show()

"""### Melakukan Analisis Korelasi pada Setiap Fitur"""

# Correlation matrix
corr_matrix = df.corr()

# Plot the heatmap for the correlation matrix
plt.figure(figsize=(14, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1)
plt.title('Correlation Matrix of Features')
plt.show()

"""## Data Preparation

### Penanganan Missing Value
"""

# Penanganan Missing Value dengan Mengganti Median
df.fillna(df.median(), inplace=True)

# Verifikasi bahwa tidak ada lagi missing values
print("\nJumlah missing value setelah penggantian dengan median:")
df.isnull().sum()

df.info()

"""### Melakukan feature selection"""

#feature yang memiliki coeficient korelasi kurang dari 0.05
feature_drop = ['education', 'currentSmoker', 'heartRate']
#dim_reduction
df = df.drop(columns=feature_drop)
df.info()

"""### Upsampling kelas minoritas"""

# Memisahkan kelas mayoritas dan minoritas
df_majority = df[df.TenYearCHD == 0]
df_minority = df[df.TenYearCHD == 1]

from sklearn.utils import resample

# Upsampling kelas minoritas
df_minority_upsampled = resample(df_minority,
                                 replace=True,  # Sample dengan replacement
                                 n_samples=len(df_majority),  # Sesuaikan jumlah mayoritas
                                 random_state=42)  # Untuk reproducibility

# Gabungkan kembali dataset mayoritas dan minoritas yang di-upsample
df_upsampled = pd.concat([df_majority, df_minority_upsampled])

df_upsampled['TenYearCHD'].value_counts()

"""### Melakukan Train Test Split"""

from sklearn.model_selection import train_test_split

# Train-test split
x = df_upsampled.drop(columns='TenYearCHD')
y = df_upsampled['TenYearCHD']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""### Melakukan Standarisasi"""

from sklearn.preprocessing import StandardScaler

# Standardize the features
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

"""## Modelling

### Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(x_train, y_train)
rf_predictions = rf_model.predict(x_test)

"""### Logistic Regression"""

lr_model = LogisticRegression(penalty='l2', C=1.0, random_state=42)
lr_model.fit(x_train, y_train)
lr_predictions = lr_model.predict(x_test)

"""### K-Nearest Neighbor"""

knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform')
knn_model.fit(x_train, y_train)
knn_predictions = knn_model.predict(x_test)

"""## Evaluation

### Hasil Evaluasi Random Forest
"""

from sklearn.metrics import classification_report

# Classification Reports
rf_classification_report = classification_report(y_test, rf_predictions)
lr_classification_report = classification_report(y_test, lr_predictions)
knn_classification_report = classification_report(y_test, knn_predictions)

print("Random Forest Classification Report:\n", rf_classification_report)

"""### Hasil Evaluasi Logistic Regression"""

print("Logistic Regression Classification Report:\n", lr_classification_report)

"""### Hasil Evaluasi K-Nearest Neighbor"""

print("K-Nearest Neighbor Classification Report:\n", knn_classification_report)